{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Mf98F8stRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564770ce-359c-466b-8d4d-14ca84d20821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phidata\n",
            "  Downloading phidata-2.7.10-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.11/dist-packages (from phidata) (0.16)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from phidata) (3.1.44)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from phidata) (0.28.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from phidata) (2.10.6)\n",
            "Collecting pydantic-settings (from phidata)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting python-dotenv (from phidata)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from phidata) (6.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from phidata) (13.9.4)\n",
            "Collecting tomli (from phidata)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from phidata) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from phidata) (4.12.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->phidata) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->phidata) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->phidata) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->phidata) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->phidata) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->phidata) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->phidata) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->phidata) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->phidata) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->phidata) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->phidata) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->phidata) (1.5.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->phidata) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->phidata) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->phidata) (1.3.1)\n",
            "Downloading phidata-2.7.10-py3-none-any.whl (716 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m716.9/716.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tomli, python-dotenv, pydantic-settings, phidata\n",
            "Successfully installed phidata-2.7.10 pydantic-settings-2.8.1 python-dotenv-1.0.1 tomli-2.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install phidata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GROQ_API_KEY = \"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\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e8Apa_mYPAX",
        "outputId": "0b379de5-bd71-4f37-be79-f09944f1468c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW8ORdaOYjLV",
        "outputId": "40c0dfa6-3157-4294-e8a6-738a2cc9d5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.0.1)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: dotenv\n",
            "Successfully installed dotenv-0.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndgZwfVZYxa8",
        "outputId": "20ab8b99-3e0e-48be-d62c-50474f806181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.19.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.19.0-py3-none-any.whl (122 kB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/122.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m112.6/122.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.2/122.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phi.agent import Agent\n",
        "from phi.model.groq import Groq\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB1h3Q8VZDo4",
        "outputId": "3bf08749-5b66-4b4d-d6eb-d997b3551494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(model = Groq(id=\"deepseek-r1-distill-llama-70b\"))"
      ],
      "metadata": {
        "id": "wTaCJW0FZkV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.print_response(\"How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTtYQIGcfugw",
        "outputId": "392e9a40-104a-45c5-c959-6d8d9e5e174b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â”â” Message â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ How are you?                                                                                     â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\n",
            "â”â” Response (1.4s) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ <think>                                                                                          â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ </think>                                                                                         â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help    â”ƒ\n",
            "â”ƒ you with whatever you need. How can I assist you today? ğŸ˜Š                                       â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.print_response(\"hi?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1en-vXiDnpax",
        "outputId": "38cfc5ca-75d6-4e11-b224-f915d3f1b4a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â”â” Message â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ hi?                                                                                              â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\n",
            "â”â” Response (0.7s) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ <think>                                                                                          â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ </think>                                                                                         â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Hello! How can I assist you today? ğŸ˜Š                                                            â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpwHGcQZrKTX",
        "outputId": "6288af3e-05b2-4834-d6ec-2015b10a5a7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phi.tools.youtube_tools import YouTubeTools\n",
        "\n",
        "youtupe_agent = Agent(\n",
        "    model = Groq(id=\"deepseek-r1-distill-llama-70b\"),\n",
        "    tools=[YouTubeTools()],\n",
        "    show_tool_calls=True,\n",
        "    description=\"You are a YouTube agent. Obtain the captions of a YouTube video and answer questions.\",\n",
        ")\n",
        "\n",
        "youtupe_agent.print_response(\"Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t\", markdown=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf-GnJEErXe-",
        "outputId": "b7d52978-aa85-4584-bfac-414c0eaa2f78"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â”â” Message â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t                               â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\n",
            "â”â” Response (10.0s) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Running:                                                                                         â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ  â€¢ get_youtube_video_captions(url=https://www.youtube.com/watch?v=Iv9dewmcFbs&t)                 â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“ â”ƒ\n",
            "â”ƒ â”ƒ              Video Summary: Building a Research Assistant with LLaMA 3 on Grok               â”ƒ â”ƒ\n",
            "â”ƒ â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”› â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ The video demonstrates how to build a research assistant powered by the LLaMA 3 model running on â”ƒ\n",
            "â”ƒ Grok. Here's a breakdown of the key points:                                                      â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ  1 Objective: The goal is to create an AI-powered research assistant that can take a complex     â”ƒ\n",
            "â”ƒ    topic, search the web for relevant information, package the findings, and generate a research â”ƒ\n",
            "â”ƒ    report using LLaMA 3.                                                                         â”ƒ\n",
            "â”ƒ  2 Setup:                                                                                        â”ƒ\n",
            "â”ƒ     â€¢ Clone the repository from the FI data repo.                                                â”ƒ\n",
            "â”ƒ     â€¢ Navigate to the cookbook/llm/groc/research folder.                                         â”ƒ\n",
            "â”ƒ     â€¢ Follow the step-by-step instructions in the README file.                                   â”ƒ\n",
            "â”ƒ  3 Steps to Run the Application:                                                                 â”ƒ\n",
            "â”ƒ     â€¢ Create a virtual environment in your terminal.                                             â”ƒ\n",
            "â”ƒ     â€¢ Export your Grok API key and T API key (for web search).                                   â”ƒ\n",
            "â”ƒ     â€¢ Install the required libraries (e.g., groc, fdata, streamlit, tavil).                      â”ƒ\n",
            "â”ƒ     â€¢ Run the Streamlit application, which serves as the interface for the research assistant.   â”ƒ\n",
            "â”ƒ  4 Functionality:                                                                                â”ƒ\n",
            "â”ƒ     â€¢ The research assistant takes a topic as input.                                             â”ƒ\n",
            "â”ƒ     â€¢ It searches the web for relevant information.                                              â”ƒ\n",
            "â”ƒ     â€¢ It packages the findings into a markdown format.                                           â”ƒ\n",
            "â”ƒ     â€¢ It sends the data to LLaMA 3, which generates a research report.                           â”ƒ\n",
            "â”ƒ  5 Features:                                                                                     â”ƒ\n",
            "â”ƒ     â€¢ The report includes a title, sections, conclusion, and references.                         â”ƒ\n",
            "â”ƒ     â€¢ Users can customize the report format according to their preferences.                      â”ƒ\n",
            "â”ƒ  6 Examples:                                                                                     â”ƒ\n",
            "â”ƒ     â€¢ Demonstrates the assistant's capabilities with topics like \"AI in Healthcare\" and          â”ƒ\n",
            "â”ƒ       \"Language Agent Research.\"                                                                 â”ƒ\n",
            "â”ƒ     â€¢ Highlights the speed of the process, with most time spent on web searches and rapid        â”ƒ\n",
            "â”ƒ       generation by LLaMA 3.                                                                     â”ƒ\n",
            "â”ƒ  7 Outcome: By the end of the video, viewers have a functional research assistant that can be    â”ƒ\n",
            "â”ƒ    tailored to their needs.                                                                      â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ This video provides a practical guide to leveraging cutting-edge AI models for efficient         â”ƒ\n",
            "â”ƒ research and reporting.                                                                          â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U googlesearch-python pycountry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xq5GiwwsL4v",
        "outputId": "5551cb9a-ecff-4a58-f68b-f374a91dcca6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pycountry\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (4.13.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (2025.1.31)\n",
            "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycountry, googlesearch-python\n",
            "Successfully installed googlesearch-python-1.3.0 pycountry-24.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phi.tools.googlesearch import GoogleSearch\n",
        "\n",
        "web_agent = Agent(\n",
        "    model = Groq(id=\"deepseek-r1-distill-llama-70b\"),\n",
        "    tools=[GoogleSearch()],\n",
        "    description=\"You are a news agent that helps users find the latest news.\",\n",
        "    instructions=[\n",
        "        \"Given a topic by the user, respond with 4 latest news items about that topic.\",\n",
        "        \"Search for 10 news items and select the top 4 unique items.\",\n",
        "        \"Search in English and in French.\",\n",
        "    ],\n",
        "    show_tool_calls=True,\n",
        "    #debug_mode=True,\n",
        ")\n",
        "web_agent.print_response(\"Mistral AI\", markdown=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KM9nHoXsWud",
        "outputId": "b00aace8-7f2c-40dc-98a1-d17bd0436323"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â”â” Message â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Mistral AI                                                                                       â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\n",
            "â”â” Response (6.5s) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Running:                                                                                         â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ  â€¢ google_search(language=en, max_results=10, query=Mistral AI latest news)                      â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Here are the latest news items about Mistral AI:                                                 â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ  1 Mistral AI Launches New Open-Source Model                                                     â”ƒ\n",
            "â”ƒ     â€¢ Mistral AI has released a new open-source model that outperforms GPT-4o Mini with a        â”ƒ\n",
            "â”ƒ       fraction of the parameters. This model is designed to be efficient and lightweight, making â”ƒ\n",
            "â”ƒ       it accessible for a wide range of applications.                                            â”ƒ\n",
            "â”ƒ     â€¢ Read more                                                                                  â”ƒ\n",
            "â”ƒ  2 Mistral AI Partners with Cisco to Transform Customer Experience                               â”ƒ\n",
            "â”ƒ     â€¢ Mistral AI has announced a strategic partnership with Cisco to deliver advanced AI         â”ƒ\n",
            "â”ƒ       solutions aimed at transforming the customer experience. This collaboration is part of     â”ƒ\n",
            "â”ƒ       Cisco's mission to integrate AI into its customer service platforms.                       â”ƒ\n",
            "â”ƒ     â€¢ Read more                                                                                  â”ƒ\n",
            "â”ƒ  3 Mistral AI Releases Regional Model for Arabic Language and Culture                            â”ƒ\n",
            "â”ƒ     â€¢ Mistral AI has expanded its offerings with a new regional model focused on the Arabic      â”ƒ\n",
            "â”ƒ       language and culture. This move highlights Mistral's commitment to diversifying its AI     â”ƒ\n",
            "â”ƒ       capabilities for global markets.                                                           â”ƒ\n",
            "â”ƒ     â€¢ Read more                                                                                  â”ƒ\n",
            "â”ƒ  4 Orange and Mistral AI Join Forces to Accelerate AI Development in Europe                      â”ƒ\n",
            "â”ƒ     â€¢ Orange and Mistral AI have announced a strategic partnership to accelerate the development â”ƒ\n",
            "â”ƒ       of artificial intelligence in Europe. This collaboration aims to drive innovation and      â”ƒ\n",
            "â”ƒ       enhance AI adoption across the continent.                                                  â”ƒ\n",
            "â”ƒ     â€¢ Read more                                                                                  â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ These updates highlight Mistral AI's recent advancements, partnerships, and expansions in the AI â”ƒ\n",
            "â”ƒ space.                                                                                           â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "team_Agent =  Agent(\n",
        "    model = Groq(id=\"deepseek-r1-distill-llama-70b\"),\n",
        "    team = [youtupe_agent,web_agent],\n",
        "    instructions=(\"Summarize the report\"),\n",
        "   show_tool_calls=True,\n",
        ")"
      ],
      "metadata": {
        "id": "pPvIbX8G7_vQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team_Agent.print_response(\"Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t\", markdown=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExFnWkMj9Fkh",
        "outputId": "6b0a5973-4009-4978-bd5a-73d015dd627b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â”â” Message â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t                               â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›\n",
            "â”â” Response (8.3s) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ Running:                                                                                         â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ  â€¢ transfer_task_to_agent_0(task_description=Extract and summarize the captions from the YouTube â”ƒ\n",
            "â”ƒ    video at the provided URL., expected_output=A concise summary of the video's content in       â”ƒ\n",
            "â”ƒ    bullet points., additional_information=https://www.youtube.com/watch?v=Iv9dewmcFbs&t)         â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ                                  Summary of the YouTube Video:                                   â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”ƒ  â€¢ Introduction:                                                                                 â”ƒ\n",
            "â”ƒ     â€¢ The video introduces a tutorial on building a research assistant using Llama 3 models on   â”ƒ\n",
            "â”ƒ       Gro.                                                                                       â”ƒ\n",
            "â”ƒ     â€¢ The application searches the web, packages information, and generates a research report    â”ƒ\n",
            "â”ƒ       using Llama 3.                                                                             â”ƒ\n",
            "â”ƒ  â€¢ Setup Instructions:                                                                           â”ƒ\n",
            "â”ƒ     â€¢ Clone the FI data repository and navigate to the specified folder.                         â”ƒ\n",
            "â”ƒ     â€¢ Create a virtual environment, export necessary API keys, install required libraries, and   â”ƒ\n",
            "â”ƒ       run the Streamlet application.                                                             â”ƒ\n",
            "â”ƒ  â€¢ Functionality:                                                                                â”ƒ\n",
            "â”ƒ     â€¢ The research assistant searches the web on a given topic, organizes results into markdown, â”ƒ\n",
            "â”ƒ       and uses Llama 3 to generate a detailed report with sections like title, conclusion, and   â”ƒ\n",
            "â”ƒ       references.                                                                                â”ƒ\n",
            "â”ƒ  â€¢ Examples:                                                                                     â”ƒ\n",
            "â”ƒ     â€¢ Demonstrates reports on topics such as \"AI in Healthcare\" and \"Language Agent Research,\"   â”ƒ\n",
            "â”ƒ       highlighting speed and quality.                                                            â”ƒ\n",
            "â”ƒ  â€¢ Customization:                                                                                â”ƒ\n",
            "â”ƒ     â€¢ Allows users to customize report formats and generation instructions.                      â”ƒ\n",
            "â”ƒ  â€¢ Conclusion:                                                                                   â”ƒ\n",
            "â”ƒ     â€¢ Encourages viewers to try the research assistant, part of the FI data repository, for      â”ƒ\n",
            "â”ƒ       adaptable use.                                                                             â”ƒ\n",
            "â”ƒ                                                                                                  â”ƒ\n",
            "â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›"
          ]
        }
      ]
    }
  ]
}