{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Mf98F8stRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "564770ce-359c-466b-8d4d-14ca84d20821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting phidata\n",
            "  Downloading phidata-2.7.10-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.11/dist-packages (from phidata) (0.16)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from phidata) (3.1.44)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from phidata) (0.28.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from phidata) (2.10.6)\n",
            "Collecting pydantic-settings (from phidata)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting python-dotenv (from phidata)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from phidata) (6.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from phidata) (13.9.4)\n",
            "Collecting tomli (from phidata)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from phidata) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from phidata) (4.12.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->phidata) (4.0.12)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->phidata) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->phidata) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->phidata) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->phidata) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->phidata) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->phidata) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->phidata) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->phidata) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->phidata) (2.18.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->phidata) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->phidata) (1.5.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->phidata) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->phidata) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->phidata) (1.3.1)\n",
            "Downloading phidata-2.7.10-py3-none-any.whl (716 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m716.9/716.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tomli, python-dotenv, pydantic-settings, phidata\n",
            "Successfully installed phidata-2.7.10 pydantic-settings-2.8.1 python-dotenv-1.0.1 tomli-2.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install phidata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GROQ_API_KEY = \"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\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e8Apa_mYPAX",
        "outputId": "0b379de5-bd71-4f37-be79-f09944f1468c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JW8ORdaOYjLV",
        "outputId": "40c0dfa6-3157-4294-e8a6-738a2cc9d5b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.0.1)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: dotenv\n",
            "Successfully installed dotenv-0.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndgZwfVZYxa8",
        "outputId": "20ab8b99-3e0e-48be-d62c-50474f806181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.19.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.19.0-py3-none-any.whl (122 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/122.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m112.6/122.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.2/122.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phi.agent import Agent\n",
        "from phi.model.groq import Groq\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB1h3Q8VZDo4",
        "outputId": "3bf08749-5b66-4b4d-d6eb-d997b3551494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(model = Groq(id=\"deepseek-r1-distill-llama-70b\"))"
      ],
      "metadata": {
        "id": "wTaCJW0FZkV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.print_response(\"How are you?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTtYQIGcfugw",
        "outputId": "392e9a40-104a-45c5-c959-6d8d9e5e174b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ How are you?                                                                                     ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
            "┏━ Response (1.4s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ <think>                                                                                          ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ </think>                                                                                         ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ Hello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help    ┃\n",
            "┃ you with whatever you need. How can I assist you today? 😊                                       ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.print_response(\"hi?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1en-vXiDnpax",
        "outputId": "38cfc5ca-75d6-4e11-b224-f915d3f1b4a7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ hi?                                                                                              ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
            "┏━ Response (0.7s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ <think>                                                                                          ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ </think>                                                                                         ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ Hello! How can I assist you today? 😊                                                            ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpwHGcQZrKTX",
        "outputId": "6288af3e-05b2-4834-d6ec-2015b10a5a7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.2-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phi.tools.youtube_tools import YouTubeTools\n",
        "\n",
        "youtupe_agent = Agent(\n",
        "    model = Groq(id=\"deepseek-r1-distill-llama-70b\"),\n",
        "    tools=[YouTubeTools()],\n",
        "    show_tool_calls=True,\n",
        "    description=\"You are a YouTube agent. Obtain the captions of a YouTube video and answer questions.\",\n",
        ")\n",
        "\n",
        "youtupe_agent.print_response(\"Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t\", markdown=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf-GnJEErXe-",
        "outputId": "b7d52978-aa85-4584-bfac-414c0eaa2f78"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t                               ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
            "┏━ Response (10.0s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ Running:                                                                                         ┃\n",
            "┃                                                                                                  ┃\n",
            "┃  • get_youtube_video_captions(url=https://www.youtube.com/watch?v=Iv9dewmcFbs&t)                 ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃\n",
            "┃ ┃              Video Summary: Building a Research Assistant with LLaMA 3 on Grok               ┃ ┃\n",
            "┃ ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛ ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ The video demonstrates how to build a research assistant powered by the LLaMA 3 model running on ┃\n",
            "┃ Grok. Here's a breakdown of the key points:                                                      ┃\n",
            "┃                                                                                                  ┃\n",
            "┃  1 Objective: The goal is to create an AI-powered research assistant that can take a complex     ┃\n",
            "┃    topic, search the web for relevant information, package the findings, and generate a research ┃\n",
            "┃    report using LLaMA 3.                                                                         ┃\n",
            "┃  2 Setup:                                                                                        ┃\n",
            "┃     • Clone the repository from the FI data repo.                                                ┃\n",
            "┃     • Navigate to the cookbook/llm/groc/research folder.                                         ┃\n",
            "┃     • Follow the step-by-step instructions in the README file.                                   ┃\n",
            "┃  3 Steps to Run the Application:                                                                 ┃\n",
            "┃     • Create a virtual environment in your terminal.                                             ┃\n",
            "┃     • Export your Grok API key and T API key (for web search).                                   ┃\n",
            "┃     • Install the required libraries (e.g., groc, fdata, streamlit, tavil).                      ┃\n",
            "┃     • Run the Streamlit application, which serves as the interface for the research assistant.   ┃\n",
            "┃  4 Functionality:                                                                                ┃\n",
            "┃     • The research assistant takes a topic as input.                                             ┃\n",
            "┃     • It searches the web for relevant information.                                              ┃\n",
            "┃     • It packages the findings into a markdown format.                                           ┃\n",
            "┃     • It sends the data to LLaMA 3, which generates a research report.                           ┃\n",
            "┃  5 Features:                                                                                     ┃\n",
            "┃     • The report includes a title, sections, conclusion, and references.                         ┃\n",
            "┃     • Users can customize the report format according to their preferences.                      ┃\n",
            "┃  6 Examples:                                                                                     ┃\n",
            "┃     • Demonstrates the assistant's capabilities with topics like \"AI in Healthcare\" and          ┃\n",
            "┃       \"Language Agent Research.\"                                                                 ┃\n",
            "┃     • Highlights the speed of the process, with most time spent on web searches and rapid        ┃\n",
            "┃       generation by LLaMA 3.                                                                     ┃\n",
            "┃  7 Outcome: By the end of the video, viewers have a functional research assistant that can be    ┃\n",
            "┃    tailored to their needs.                                                                      ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ This video provides a practical guide to leveraging cutting-edge AI models for efficient         ┃\n",
            "┃ research and reporting.                                                                          ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U googlesearch-python pycountry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xq5GiwwsL4v",
        "outputId": "5551cb9a-ecff-4a58-f68b-f374a91dcca6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting pycountry\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (4.13.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (2025.1.31)\n",
            "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycountry, googlesearch-python\n",
            "Successfully installed googlesearch-python-1.3.0 pycountry-24.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from phi.tools.googlesearch import GoogleSearch\n",
        "\n",
        "web_agent = Agent(\n",
        "    model = Groq(id=\"deepseek-r1-distill-llama-70b\"),\n",
        "    tools=[GoogleSearch()],\n",
        "    description=\"You are a news agent that helps users find the latest news.\",\n",
        "    instructions=[\n",
        "        \"Given a topic by the user, respond with 4 latest news items about that topic.\",\n",
        "        \"Search for 10 news items and select the top 4 unique items.\",\n",
        "        \"Search in English and in French.\",\n",
        "    ],\n",
        "    show_tool_calls=True,\n",
        "    #debug_mode=True,\n",
        ")\n",
        "web_agent.print_response(\"Mistral AI\", markdown=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KM9nHoXsWud",
        "outputId": "b00aace8-7f2c-40dc-98a1-d17bd0436323"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ Mistral AI                                                                                       ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
            "┏━ Response (6.5s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ Running:                                                                                         ┃\n",
            "┃                                                                                                  ┃\n",
            "┃  • google_search(language=en, max_results=10, query=Mistral AI latest news)                      ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ Here are the latest news items about Mistral AI:                                                 ┃\n",
            "┃                                                                                                  ┃\n",
            "┃  1 Mistral AI Launches New Open-Source Model                                                     ┃\n",
            "┃     • Mistral AI has released a new open-source model that outperforms GPT-4o Mini with a        ┃\n",
            "┃       fraction of the parameters. This model is designed to be efficient and lightweight, making ┃\n",
            "┃       it accessible for a wide range of applications.                                            ┃\n",
            "┃     • Read more                                                                                  ┃\n",
            "┃  2 Mistral AI Partners with Cisco to Transform Customer Experience                               ┃\n",
            "┃     • Mistral AI has announced a strategic partnership with Cisco to deliver advanced AI         ┃\n",
            "┃       solutions aimed at transforming the customer experience. This collaboration is part of     ┃\n",
            "┃       Cisco's mission to integrate AI into its customer service platforms.                       ┃\n",
            "┃     • Read more                                                                                  ┃\n",
            "┃  3 Mistral AI Releases Regional Model for Arabic Language and Culture                            ┃\n",
            "┃     • Mistral AI has expanded its offerings with a new regional model focused on the Arabic      ┃\n",
            "┃       language and culture. This move highlights Mistral's commitment to diversifying its AI     ┃\n",
            "┃       capabilities for global markets.                                                           ┃\n",
            "┃     • Read more                                                                                  ┃\n",
            "┃  4 Orange and Mistral AI Join Forces to Accelerate AI Development in Europe                      ┃\n",
            "┃     • Orange and Mistral AI have announced a strategic partnership to accelerate the development ┃\n",
            "┃       of artificial intelligence in Europe. This collaboration aims to drive innovation and      ┃\n",
            "┃       enhance AI adoption across the continent.                                                  ┃\n",
            "┃     • Read more                                                                                  ┃\n",
            "┃                                                                                                  ┃\n",
            "┃ These updates highlight Mistral AI's recent advancements, partnerships, and expansions in the AI ┃\n",
            "┃ space.                                                                                           ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "team_Agent =  Agent(\n",
        "    model = Groq(id=\"deepseek-r1-distill-llama-70b\"),\n",
        "    team = [youtupe_agent,web_agent],\n",
        "    instructions=(\"Summarize the report\"),\n",
        "   show_tool_calls=True,\n",
        ")"
      ],
      "metadata": {
        "id": "pPvIbX8G7_vQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "team_Agent.print_response(\"Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t\", markdown=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExFnWkMj9Fkh",
        "outputId": "6b0a5973-4009-4978-bd5a-73d015dd627b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "┏━ Message ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t                               ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛\n",
            "┏━ Response (8.3s) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃                                                                                                  ┃\n",
            "┃ Running:                                                                                         ┃\n",
            "┃                                                                                                  ┃\n",
            "┃  • transfer_task_to_agent_0(task_description=Extract and summarize the captions from the YouTube ┃\n",
            "┃    video at the provided URL., expected_output=A concise summary of the video's content in       ┃\n",
            "┃    bullet points., additional_information=https://www.youtube.com/watch?v=Iv9dewmcFbs&t)         ┃\n",
            "┃                                                                                                  ┃\n",
            "┃                                  Summary of the YouTube Video:                                   ┃\n",
            "┃                                                                                                  ┃\n",
            "┃  • Introduction:                                                                                 ┃\n",
            "┃     • The video introduces a tutorial on building a research assistant using Llama 3 models on   ┃\n",
            "┃       Gro.                                                                                       ┃\n",
            "┃     • The application searches the web, packages information, and generates a research report    ┃\n",
            "┃       using Llama 3.                                                                             ┃\n",
            "┃  • Setup Instructions:                                                                           ┃\n",
            "┃     • Clone the FI data repository and navigate to the specified folder.                         ┃\n",
            "┃     • Create a virtual environment, export necessary API keys, install required libraries, and   ┃\n",
            "┃       run the Streamlet application.                                                             ┃\n",
            "┃  • Functionality:                                                                                ┃\n",
            "┃     • The research assistant searches the web on a given topic, organizes results into markdown, ┃\n",
            "┃       and uses Llama 3 to generate a detailed report with sections like title, conclusion, and   ┃\n",
            "┃       references.                                                                                ┃\n",
            "┃  • Examples:                                                                                     ┃\n",
            "┃     • Demonstrates reports on topics such as \"AI in Healthcare\" and \"Language Agent Research,\"   ┃\n",
            "┃       highlighting speed and quality.                                                            ┃\n",
            "┃  • Customization:                                                                                ┃\n",
            "┃     • Allows users to customize report formats and generation instructions.                      ┃\n",
            "┃  • Conclusion:                                                                                   ┃\n",
            "┃     • Encourages viewers to try the research assistant, part of the FI data repository, for      ┃\n",
            "┃       adaptable use.                                                                             ┃\n",
            "┃                                                                                                  ┃\n",
            "┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛"
          ]
        }
      ]
    }
  ]
}